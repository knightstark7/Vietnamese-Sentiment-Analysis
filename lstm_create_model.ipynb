{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Word2Vec Model\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'underthesea'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcreateWord2VecModel\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m createW2VModel\n\u001b[0;32m      3\u001b[0m createW2VModel(models \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mskipgram\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcbow\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "File \u001b[1;32md:\\school\\Master\\NLP\\Deep-Neural-Network-Vietnamese-Student-Feedback-Sentiment-Analysis\\createWord2VecModel.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m readData, tokenizeWords\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mword2vec\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mWord2Vec\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m studentFeedbackWord2Vec\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreateW2VModel\u001b[39m(models \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mskipgram\u001b[39m\u001b[38;5;124m\"\u001b[39m]):\n",
      "File \u001b[1;32md:\\school\\Master\\NLP\\Deep-Neural-Network-Vietnamese-Student-Feedback-Sentiment-Analysis\\utils\\preprocessing.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01munderthesea\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m sent_tokenize, word_tokenize\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mre\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mstring\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'underthesea'"
     ]
    }
   ],
   "source": [
    "from createWord2VecModel import createW2VModel\n",
    "\n",
    "createW2VModel(models = [\"skipgram\", \"cbow\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Skip-gram\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'triu' from 'scipy.linalg' (C:\\Users\\Admin\\AppData\\Roaming\\Python\\Python312\\site-packages\\scipy\\linalg\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mword2vec\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mWord2Vec\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m studentFeedbackWord2Vec\n\u001b[0;32m      3\u001b[0m w2v_skipgram \u001b[38;5;241m=\u001b[39m studentFeedbackWord2Vec()\n\u001b[0;32m      4\u001b[0m w2v_skipgram\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mword2vec/skipgram_model.bin\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32md:\\school\\Master\\NLP\\Deep-Neural-Network-Vietnamese-Student-Feedback-Sentiment-Analysis\\word2vec\\Word2Vec.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgensim\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mword2vec\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Word2Vec\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgensim\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfasttext\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FastText\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\gensim\\__init__.py:11\u001b[0m\n\u001b[0;32m      7\u001b[0m __version__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m4.3.2\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mlogging\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgensim\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m parsing, corpora, matutils, interfaces, models, similarities, utils  \u001b[38;5;66;03m# noqa:F401\u001b[39;00m\n\u001b[0;32m     14\u001b[0m logger \u001b[38;5;241m=\u001b[39m logging\u001b[38;5;241m.\u001b[39mgetLogger(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgensim\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m logger\u001b[38;5;241m.\u001b[39mhandlers:  \u001b[38;5;66;03m# To ensure reload() doesn't add another one\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\gensim\\corpora\\__init__.py:6\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;124;03mThis package contains implementations of various streaming corpus I/O format.\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# bring corpus classes directly into package namespace, to save some typing\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mindexedcorpus\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m IndexedCorpus  \u001b[38;5;66;03m# noqa:F401 must appear before the other classes\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmmcorpus\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MmCorpus  \u001b[38;5;66;03m# noqa:F401\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbleicorpus\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BleiCorpus  \u001b[38;5;66;03m# noqa:F401\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\gensim\\corpora\\indexedcorpus.py:14\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mlogging\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgensim\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m interfaces, utils\n\u001b[0;32m     16\u001b[0m logger \u001b[38;5;241m=\u001b[39m logging\u001b[38;5;241m.\u001b[39mgetLogger(\u001b[38;5;18m__name__\u001b[39m)\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mIndexedCorpus\u001b[39;00m(interfaces\u001b[38;5;241m.\u001b[39mCorpusABC):\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\gensim\\interfaces.py:19\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;124;03m\"\"\"Basic interfaces used across the whole Gensim package.\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \n\u001b[0;32m      9\u001b[0m \u001b[38;5;124;03mThese interfaces are used for building corpora, model transformation and similarity queries.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     14\u001b[0m \n\u001b[0;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mlogging\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgensim\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m utils, matutils\n\u001b[0;32m     22\u001b[0m logger \u001b[38;5;241m=\u001b[39m logging\u001b[38;5;241m.\u001b[39mgetLogger(\u001b[38;5;18m__name__\u001b[39m)\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mCorpusABC\u001b[39;00m(utils\u001b[38;5;241m.\u001b[39mSaveLoad):\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\gensim\\matutils.py:20\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msparse\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstats\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m entropy\n\u001b[1;32m---> 20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinalg\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_blas_funcs, triu\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinalg\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlapack\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_lapack_funcs\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mspecial\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m psi  \u001b[38;5;66;03m# gamma function utils\u001b[39;00m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'triu' from 'scipy.linalg' (C:\\Users\\Admin\\AppData\\Roaming\\Python\\Python312\\site-packages\\scipy\\linalg\\__init__.py)"
     ]
    }
   ],
   "source": [
    "from word2vec.Word2Vec import studentFeedbackWord2Vec\n",
    "\n",
    "w2v_skipgram = studentFeedbackWord2Vec()\n",
    "w2v_skipgram.load(\"word2vec/skipgram_model.bin\")\n",
    "w2v_skipgram.most_similar(\"giảng viên\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'w2v_skipgram' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 12\u001b[0m\n\u001b[0;32m      6\u001b[0m selected_words \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthầy\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthầy giáo\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgiảng viên\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgiáo viên\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcô\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      7\u001b[0m                   \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhọc\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthực hành\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgiảng dạy\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdạy\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtruyền đạt\u001b[39m\u001b[38;5;124m\"\u001b[39m, \n\u001b[0;32m      8\u001b[0m                   \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msinh viên\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhọc sinh\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhọc viên\u001b[39m\u001b[38;5;124m\"\u001b[39m, \n\u001b[0;32m      9\u001b[0m                   \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlôi cuốn\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtruyền cảm hứng\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhay\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msâu rộng\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Lấy vector của các từ từ mô hình\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m vectors \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([\u001b[43mw2v_skipgram\u001b[49m\u001b[38;5;241m.\u001b[39mget_vector(word) \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m selected_words])\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Giảm chiều dữ liệu về 2 chiều bằng t-SNE\u001b[39;00m\n\u001b[0;32m     15\u001b[0m tsne \u001b[38;5;241m=\u001b[39m TSNE(n_components\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, perplexity\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m ,random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'w2v_skipgram' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# Chọn các từ bạn muốn vẽ\n",
    "selected_words = [\"thầy\", \"thầy giáo\",\"giảng viên\", \"giáo viên\", \"cô\",\n",
    "                  \"học\", \"thực hành\", \"giảng dạy\", \"dạy\", \"truyền đạt\", \n",
    "                  \"sinh viên\", \"học sinh\", \"học viên\", \n",
    "                  \"lôi cuốn\", \"truyền cảm hứng\", \"hay\", \"sâu rộng\"]\n",
    "\n",
    "# Lấy vector của các từ từ mô hình\n",
    "vectors = np.array([w2v_skipgram.get_vector(word) for word in selected_words])\n",
    "\n",
    "# Giảm chiều dữ liệu về 2 chiều bằng t-SNE\n",
    "tsne = TSNE(n_components=2, perplexity=5 ,random_state=42)\n",
    "vectors_2d = tsne.fit_transform(vectors)\n",
    "\n",
    "# Vẽ biểu đồ\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(vectors_2d[:, 0], vectors_2d[:, 1], marker='.', color='b')\n",
    "\n",
    "# Hiển thị tên của các từ\n",
    "for i, word in enumerate(selected_words):\n",
    "    plt.annotate(word, xy=(vectors_2d[i, 0], vectors_2d[i, 1]), fontsize=12)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1417, 200)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.04706901,  0.04697308,  0.12053639, ..., -0.10975017,\n",
       "        -0.14133483,  0.09999546],\n",
       "       [-0.02706477, -0.21032779, -0.12009019, ..., -0.1416798 ,\n",
       "         0.0310597 , -0.22083569],\n",
       "       [-0.02754532,  0.05829177, -0.07787398, ..., -0.32446513,\n",
       "        -0.06499125, -0.03382463],\n",
       "       ...,\n",
       "       [ 0.04703511,  0.00425424, -0.05081932, ..., -0.13321182,\n",
       "         0.10176032, -0.098496  ],\n",
       "       [ 0.0546285 , -0.14185156,  0.10670795, ..., -0.22149621,\n",
       "        -0.06195882, -0.04163087],\n",
       "       [ 0.06285618,  0.04265485, -0.00717064, ..., -0.04289993,\n",
       "         0.0214246 , -0.12970564]], dtype=float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(w2v_skipgram.get_vectors().shape)\n",
    "w2v_skipgram.get_vectors()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Skipgram Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "words = dict()\n",
    "    \n",
    "for word in w2v_skipgram.get_vocab():\n",
    "    words[word] = w2v_skipgram.get_vector(word)\n",
    "    \n",
    "with open(\"utils/words_dict.pkl\", 'wb') as file:\n",
    "    pkl.dump(words, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Vectorizer\n",
    "with open(\"utils/words_dict.pkl\", \"rb\") as file:\n",
    "    words = pkl.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Processing\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting underthesea\n",
      "  Using cached underthesea-6.8.3-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting Click>=6.0 (from underthesea)\n",
      "  Using cached click-8.1.7-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting python-crfsuite>=0.9.6 (from underthesea)\n",
      "  Using cached python_crfsuite-0.9.10-cp312-cp312-win_amd64.whl.metadata (4.3 kB)\n",
      "Collecting nltk (from underthesea)\n",
      "  Using cached nltk-3.8.1-py3-none-any.whl.metadata (2.8 kB)\n",
      "Requirement already satisfied: tqdm in c:\\users\\admin\\appdata\\roaming\\python\\python312\\site-packages (from underthesea) (4.66.4)\n",
      "Requirement already satisfied: requests in c:\\users\\admin\\appdata\\roaming\\python\\python312\\site-packages (from underthesea) (2.32.3)\n",
      "Requirement already satisfied: joblib in c:\\users\\admin\\appdata\\roaming\\python\\python312\\site-packages (from underthesea) (1.4.2)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\admin\\appdata\\roaming\\python\\python312\\site-packages (from underthesea) (1.4.2)\n",
      "Requirement already satisfied: PyYAML in c:\\users\\admin\\appdata\\roaming\\python\\python312\\site-packages (from underthesea) (6.0.1)\n",
      "Collecting underthesea-core==1.0.4 (from underthesea)\n",
      "  Using cached underthesea_core-1.0.4.tar.gz (560 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Exception:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Program Files\\Python312\\Lib\\site-packages\\pip\\_internal\\cli\\base_command.py\", line 180, in exc_logging_wrapper\n",
      "    status = run_func(*args)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Program Files\\Python312\\Lib\\site-packages\\pip\\_internal\\cli\\req_command.py\", line 245, in wrapper\n",
      "    return func(self, options, args)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Program Files\\Python312\\Lib\\site-packages\\pip\\_internal\\commands\\install.py\", line 377, in run\n",
      "    requirement_set = resolver.resolve(\n",
      "                      ^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Program Files\\Python312\\Lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\resolver.py\", line 95, in resolve\n",
      "    result = self._result = resolver.resolve(\n",
      "                            ^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Program Files\\Python312\\Lib\\site-packages\\pip\\_vendor\\resolvelib\\resolvers.py\", line 546, in resolve\n",
      "    state = resolution.resolve(requirements, max_rounds=max_rounds)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Program Files\\Python312\\Lib\\site-packages\\pip\\_vendor\\resolvelib\\resolvers.py\", line 427, in resolve\n",
      "    failure_causes = self._attempt_to_pin_criterion(name)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Program Files\\Python312\\Lib\\site-packages\\pip\\_vendor\\resolvelib\\resolvers.py\", line 239, in _attempt_to_pin_criterion\n",
      "    criteria = self._get_updated_criteria(candidate)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Program Files\\Python312\\Lib\\site-packages\\pip\\_vendor\\resolvelib\\resolvers.py\", line 230, in _get_updated_criteria\n",
      "    self._add_to_criteria(criteria, requirement, parent=candidate)\n",
      "  File \"C:\\Program Files\\Python312\\Lib\\site-packages\\pip\\_vendor\\resolvelib\\resolvers.py\", line 173, in _add_to_criteria\n",
      "    if not criterion.candidates:\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Program Files\\Python312\\Lib\\site-packages\\pip\\_vendor\\resolvelib\\structs.py\", line 156, in __bool__\n",
      "    return bool(self._sequence)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Program Files\\Python312\\Lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\found_candidates.py\", line 155, in __bool__\n",
      "    return any(self)\n",
      "           ^^^^^^^^^\n",
      "  File \"C:\\Program Files\\Python312\\Lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\found_candidates.py\", line 143, in <genexpr>\n",
      "    return (c for c in iterator if id(c) not in self._incompatible_ids)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Program Files\\Python312\\Lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\found_candidates.py\", line 47, in _iter_built\n",
      "    candidate = func()\n",
      "                ^^^^^^\n",
      "  File \"C:\\Program Files\\Python312\\Lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\factory.py\", line 182, in _make_candidate_from_link\n",
      "    base: Optional[BaseCandidate] = self._make_base_candidate_from_link(\n",
      "                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Program Files\\Python312\\Lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\factory.py\", line 228, in _make_base_candidate_from_link\n",
      "    self._link_candidate_cache[link] = LinkCandidate(\n",
      "                                       ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Program Files\\Python312\\Lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\candidates.py\", line 290, in __init__\n",
      "    super().__init__(\n",
      "  File \"C:\\Program Files\\Python312\\Lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\candidates.py\", line 156, in __init__\n",
      "    self.dist = self._prepare()\n",
      "                ^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Program Files\\Python312\\Lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\candidates.py\", line 222, in _prepare\n",
      "    dist = self._prepare_distribution()\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Program Files\\Python312\\Lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\candidates.py\", line 301, in _prepare_distribution\n",
      "    return preparer.prepare_linked_requirement(self._ireq, parallel_builds=True)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Program Files\\Python312\\Lib\\site-packages\\pip\\_internal\\operations\\prepare.py\", line 525, in prepare_linked_requirement\n",
      "    return self._prepare_linked_requirement(req, parallel_builds)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Program Files\\Python312\\Lib\\site-packages\\pip\\_internal\\operations\\prepare.py\", line 640, in _prepare_linked_requirement\n",
      "    dist = _get_prepared_distribution(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Program Files\\Python312\\Lib\\site-packages\\pip\\_internal\\operations\\prepare.py\", line 71, in _get_prepared_distribution\n",
      "    abstract_dist.prepare_distribution_metadata(\n",
      "  File \"C:\\Program Files\\Python312\\Lib\\site-packages\\pip\\_internal\\distributions\\sdist.py\", line 54, in prepare_distribution_metadata\n",
      "    self._install_build_reqs(finder)\n",
      "  File \"C:\\Program Files\\Python312\\Lib\\site-packages\\pip\\_internal\\distributions\\sdist.py\", line 124, in _install_build_reqs\n",
      "    build_reqs = self._get_build_requires_wheel()\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Program Files\\Python312\\Lib\\site-packages\\pip\\_internal\\distributions\\sdist.py\", line 101, in _get_build_requires_wheel\n",
      "    return backend.get_requires_for_build_wheel()\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Program Files\\Python312\\Lib\\site-packages\\pip\\_internal\\utils\\misc.py\", line 745, in get_requires_for_build_wheel\n",
      "    return super().get_requires_for_build_wheel(config_settings=cs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Program Files\\Python312\\Lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_impl.py\", line 166, in get_requires_for_build_wheel\n",
      "    return self._call_hook('get_requires_for_build_wheel', {\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Program Files\\Python312\\Lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_impl.py\", line 321, in _call_hook\n",
      "    raise BackendUnavailable(data.get('traceback', ''))\n",
      "pip._vendor.pyproject_hooks._impl.BackendUnavailable: Traceback (most recent call last):\n",
      "  File \"C:\\Program Files\\Python312\\Lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\", line 77, in _build_backend\n",
      "    obj = import_module(mod_path)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Program Files\\Python312\\Lib\\importlib\\__init__.py\", line 90, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"<frozen importlib._bootstrap>\", line 1387, in _gcd_import\n",
      "  File \"<frozen importlib._bootstrap>\", line 1360, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 1324, in _find_and_load_unlocked\n",
      "ModuleNotFoundError: No module named 'maturin'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!pip install underthesea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'underthesea'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01munderthesea\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m word_tokenize\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m remove_punctuation\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtokenize_vietnamese_sentence\u001b[39m(sentence):\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'underthesea'"
     ]
    }
   ],
   "source": [
    "from underthesea import word_tokenize\n",
    "from utils.preprocessing import remove_punctuation\n",
    "\n",
    "def tokenize_vietnamese_sentence(sentence):\n",
    "    return word_tokenize(remove_punctuation(sentence.lower()))\n",
    "\n",
    "def sent2vec(message, word_dict = words):\n",
    "    tokens = tokenize_vietnamese_sentence(message)\n",
    "    vectors = []\n",
    "    \n",
    "    for token in tokens:\n",
    "        if token not in word_dict.keys():\n",
    "            continue\n",
    "        token_vector = word_dict[token]\n",
    "        vectors.append(token_vector)\n",
    "    return np.array(vectors, dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 200)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent2vec(\"thầy dạy tốt.\").shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "train_df = pd.read_csv(\"Data/train.csv\")\n",
    "dev_df   = pd.read_csv(\"Data/dev.csv\")\n",
    "test_df  = pd.read_csv(\"Data/test.csv\")\n",
    "\n",
    "X_train, y_train = train_df[\"sents\"], train_df[\"sentiments\"]\n",
    "X_dev, y_dev = dev_df[\"sents\"], dev_df[\"sentiments\"]\n",
    "X_test, y_test = test_df[\"sents\"], test_df[\"sentiments\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11426, 1583, 3166)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_df), len(dev_df), len(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_to_X_y(dataframe):\n",
    "    y = dataframe[\"sentiments\"].to_numpy().astype(int)\n",
    "    \n",
    "    all_word_vector_sequences = []\n",
    "    \n",
    "    for message in dataframe[\"sents\"]:\n",
    "      message_as_vector_seq = sent2vec(message)\n",
    "      if message_as_vector_seq.shape[0] == 0:\n",
    "        message_as_vector_seq = np.zeros(shape=(1, 200))\n",
    "\n",
    "      all_word_vector_sequences.append(message_as_vector_seq)\n",
    "    \n",
    "    return all_word_vector_sequences, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11426 3\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train = df_to_X_y(train_df)\n",
    "\n",
    "print(len(X_train), len(X_train[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11426 5\n"
     ]
    }
   ],
   "source": [
    "print(len(X_train), len(X_train[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([8.174e+03, 2.439e+03, 5.870e+02, 1.460e+02, 5.000e+01, 2.100e+01,\n",
       "        5.000e+00, 1.000e+00, 1.000e+00, 2.000e+00]),\n",
       " array([ 1. , 10.7, 20.4, 30.1, 39.8, 49.5, 59.2, 68.9, 78.6, 88.3, 98. ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjEAAAGdCAYAAADjWSL8AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAAAuoUlEQVR4nO3df3RU5YH/8c+YH2OSJrckITNOjRLP5iAYtBrckOgWWiBgiVmPPYJGp3hk+VEUnALlR+1u0VMToFtw22wpsh6xgBtPT43rKk0JrU1lISRGpwUEtccIQTIE22ESNJtguN8/PN7vDkHMhEB44vt1zv0j937mznMfOc7nPJl747Jt2xYAAIBhLhvsAQAAAPQHJQYAABiJEgMAAIxEiQEAAEaixAAAACNRYgAAgJEoMQAAwEiUGAAAYKT4wR7AhXL69GkdPXpUqampcrlcgz0cAADQB7Ztq6OjQz6fT5dddu61liFbYo4ePars7OzBHgYAAOiHlpYWXXnllefMDNkSk5qaKumTSUhLSxvk0QAAgL5ob29Xdna28zl+LkO2xHz6K6S0tDRKDAAAhunLV0H4Yi8AADASJQYAABiJEgMAAIxEiQEAAEaixAAAACNRYgAAgJEoMQAAwEiUGAAAYCRKDAAAMBIlBgAAGIkSAwAAjESJAQAARqLEAAAAI1FiAACAkeIHewCmGrH85cEeQszeWzVtsIcAAMCAYSUGAAAYiRIDAACMRIkBAABGiqnEfPzxx/rBD36gnJwcJSUl6ZprrtFjjz2m06dPOxnbtrVy5Ur5fD4lJSVpwoQJ2r9/f9R5urq6tGDBAmVmZiolJUWlpaU6cuRIVCYcDsvv98uyLFmWJb/frxMnTvT/SgEAwJASU4lZvXq1fvGLX6iyslIHDhzQmjVr9OMf/1g/+9nPnMyaNWu0du1aVVZWqrGxUV6vV5MnT1ZHR4eTCQQCqq6uVlVVlXbu3KmTJ0+qpKREPT09TqasrEzBYFA1NTWqqalRMBiU3+8fgEsGAABDgcu2bbuv4ZKSEnk8Hj311FPOvm9961tKTk7W5s2bZdu2fD6fAoGAli1bJumTVRePx6PVq1dr7ty5ikQiGj58uDZv3qwZM2ZIko4ePars7Gxt27ZNU6ZM0YEDBzR69GjV19eroKBAklRfX6/CwkIdPHhQI0eO/Nyxtre3y7IsRSIRpaWlxTQpfcHdSQAADLxYPr9jWom59dZb9bvf/U5vv/22JOlPf/qTdu7cqW9+85uSpObmZoVCIRUXFzuvcbvdGj9+vHbt2iVJampq0qlTp6IyPp9PeXl5Tmb37t2yLMspMJI0btw4WZblZM7U1dWl9vb2qA0AAAxdMT0nZtmyZYpEIrr22msVFxennp4ePf7447rnnnskSaFQSJLk8XiiXufxeHTo0CEnk5iYqGHDhvXKfPr6UCikrKysXu+flZXlZM5UUVGhRx99NJbLAQAABotpJea5557Tli1b9Oyzz+r111/XM888o3/913/VM888E5VzuVxRP9u23Wvfmc7MnC1/rvOsWLFCkUjE2VpaWvp6WQAAwEAxrcR873vf0/Lly3X33XdLksaMGaNDhw6poqJCM2fOlNfrlfTJSsoVV1zhvK6trc1ZnfF6veru7lY4HI5ajWlra1NRUZGTOXbsWK/3P378eK9Vnk+53W653e5YLgcAABgsppWYjz76SJddFv2SuLg45xbrnJwceb1e1dbWOse7u7tVV1fnFJT8/HwlJCREZVpbW7Vv3z4nU1hYqEgkooaGBiezZ88eRSIRJwMAAL7YYlqJuf322/X444/rqquu0nXXXac33nhDa9eu1QMPPCDpk18BBQIBlZeXKzc3V7m5uSovL1dycrLKysokSZZladasWVq8eLEyMjKUnp6uJUuWaMyYMZo0aZIkadSoUZo6dapmz56tDRs2SJLmzJmjkpKSPt2ZBAAAhr6YSszPfvYz/fM//7Pmz5+vtrY2+Xw+zZ07V//yL//iZJYuXarOzk7Nnz9f4XBYBQUF2r59u1JTU53MunXrFB8fr+nTp6uzs1MTJ07Upk2bFBcX52S2bt2qhQsXOncxlZaWqrKy8nyvFwAADBExPSfGJDwnpjeeEwMAuNRdsOfEAAAAXCooMQAAwEiUGAAAYCRKDAAAMBIlBgAAGIkSAwAAjESJAQAARqLEAAAAI1FiAACAkSgxAADASJQYAABgJEoMAAAwEiUGAAAYiRIDAACMRIkBAABGosQAAAAjUWIAAICRKDEAAMBIlBgAAGAkSgwAADASJQYAABiJEgMAAIxEiQEAAEaixAAAACNRYgAAgJEoMQAAwEiUGAAAYCRKDAAAMBIlBgAAGIkSAwAAjESJAQAARqLEAAAAI8VUYkaMGCGXy9Vre/DBByVJtm1r5cqV8vl8SkpK0oQJE7R///6oc3R1dWnBggXKzMxUSkqKSktLdeTIkahMOByW3++XZVmyLEt+v18nTpw4vysFAABDSkwlprGxUa2trc5WW1srSbrrrrskSWvWrNHatWtVWVmpxsZGeb1eTZ48WR0dHc45AoGAqqurVVVVpZ07d+rkyZMqKSlRT0+PkykrK1MwGFRNTY1qamoUDAbl9/sH4noBAMAQ4bJt2+7viwOBgF566SW98847kiSfz6dAIKBly5ZJ+mTVxePxaPXq1Zo7d64ikYiGDx+uzZs3a8aMGZKko0ePKjs7W9u2bdOUKVN04MABjR49WvX19SooKJAk1dfXq7CwUAcPHtTIkSP7NLb29nZZlqVIJKK0tLT+XuJnGrH85QE/54X23qppgz0EAADOKZbP735/J6a7u1tbtmzRAw88IJfLpebmZoVCIRUXFzsZt9ut8ePHa9euXZKkpqYmnTp1Kirj8/mUl5fnZHbv3i3LspwCI0njxo2TZVlO5my6urrU3t4etQEAgKGr3yXmhRde0IkTJ3T//fdLkkKhkCTJ4/FE5Twej3MsFAopMTFRw4YNO2cmKyur1/tlZWU5mbOpqKhwvkNjWZays7P7e2kAAMAA/S4xTz31lG677Tb5fL6o/S6XK+pn27Z77TvTmZmz5T/vPCtWrFAkEnG2lpaWvlwGAAAwVL9KzKFDh7Rjxw790z/9k7PP6/VKUq/Vkra2Nmd1xuv1qru7W+Fw+JyZY8eO9XrP48eP91rl+b/cbrfS0tKiNgAAMHT1q8Q8/fTTysrK0rRp//+Lojk5OfJ6vc4dS9In35upq6tTUVGRJCk/P18JCQlRmdbWVu3bt8/JFBYWKhKJqKGhwcns2bNHkUjEyQAAAMTH+oLTp0/r6aef1syZMxUf//9f7nK5FAgEVF5ertzcXOXm5qq8vFzJyckqKyuTJFmWpVmzZmnx4sXKyMhQenq6lixZojFjxmjSpEmSpFGjRmnq1KmaPXu2NmzYIEmaM2eOSkpK+nxnEgAAGPpiLjE7duzQ4cOH9cADD/Q6tnTpUnV2dmr+/PkKh8MqKCjQ9u3blZqa6mTWrVun+Ph4TZ8+XZ2dnZo4caI2bdqkuLg4J7N161YtXLjQuYuptLRUlZWV/bk+AAAwRJ3Xc2IuZTwnpjeeEwMAuNRdlOfEAAAADCZKDAAAMBIlBgAAGIkSAwAAjESJAQAARqLEAAAAI1FiAACAkSgxAADASJQYAABgJEoMAAAwEiUGAAAYiRIDAACMRIkBAABGosQAAAAjUWIAAICRKDEAAMBIlBgAAGAkSgwAADASJQYAABiJEgMAAIxEiQEAAEaixAAAACNRYgAAgJEoMQAAwEiUGAAAYCRKDAAAMBIlBgAAGIkSAwAAjESJAQAARqLEAAAAI1FiAACAkSgxAADASDGXmPfff1/33XefMjIylJycrK9+9atqampyjtu2rZUrV8rn8ykpKUkTJkzQ/v37o87R1dWlBQsWKDMzUykpKSotLdWRI0eiMuFwWH6/X5ZlybIs+f1+nThxon9XCQAAhpyYSkw4HNYtt9yihIQE/eY3v9Gbb76pn/zkJ/ryl7/sZNasWaO1a9eqsrJSjY2N8nq9mjx5sjo6OpxMIBBQdXW1qqqqtHPnTp08eVIlJSXq6elxMmVlZQoGg6qpqVFNTY2CwaD8fv/5XzEAABgSXLZt230NL1++XP/zP/+jV1999azHbduWz+dTIBDQsmXLJH2y6uLxeLR69WrNnTtXkUhEw4cP1+bNmzVjxgxJ0tGjR5Wdna1t27ZpypQpOnDggEaPHq36+noVFBRIkurr61VYWKiDBw9q5MiRnzvW9vZ2WZalSCSitLS0vl5in41Y/vKAn/NCe2/VtMEeAgAA5xTL53dMKzEvvviixo4dq7vuuktZWVm68cYbtXHjRud4c3OzQqGQiouLnX1ut1vjx4/Xrl27JElNTU06depUVMbn8ykvL8/J7N69W5ZlOQVGksaNGyfLspzMmbq6utTe3h61AQCAoSumEvPuu+9q/fr1ys3N1W9/+1vNmzdPCxcu1C9/+UtJUigUkiR5PJ6o13k8HudYKBRSYmKihg0bds5MVlZWr/fPyspyMmeqqKhwvj9jWZays7NjuTQAAGCYmErM6dOnddNNN6m8vFw33nij5s6dq9mzZ2v9+vVROZfLFfWzbdu99p3pzMzZ8uc6z4oVKxSJRJytpaWlr5cFAAAMFFOJueKKKzR69OiofaNGjdLhw4clSV6vV5J6rZa0tbU5qzNer1fd3d0Kh8PnzBw7dqzX+x8/frzXKs+n3G630tLSojYAADB0xVRibrnlFr311ltR+95++21dffXVkqScnBx5vV7V1tY6x7u7u1VXV6eioiJJUn5+vhISEqIyra2t2rdvn5MpLCxUJBJRQ0ODk9mzZ48ikYiTAQAAX2zxsYS/+93vqqioSOXl5Zo+fboaGhr05JNP6sknn5T0ya+AAoGAysvLlZubq9zcXJWXlys5OVllZWWSJMuyNGvWLC1evFgZGRlKT0/XkiVLNGbMGE2aNEnSJ6s7U6dO1ezZs7VhwwZJ0pw5c1RSUtKnO5MAAMDQF1OJufnmm1VdXa0VK1boscceU05Ojp544gnde++9Tmbp0qXq7OzU/PnzFQ6HVVBQoO3btys1NdXJrFu3TvHx8Zo+fbo6Ozs1ceJEbdq0SXFxcU5m69atWrhwoXMXU2lpqSorK8/3egEAwBAR03NiTMJzYnrjOTEAgEvdBXtODAAAwKWCEgMAAIxEiQEAAEaixAAAACNRYgAAgJEoMQAAwEiUGAAAYCRKDAAAMBIlBgAAGIkSAwAAjESJAQAARqLEAAAAI1FiAACAkSgxAADASJQYAABgJEoMAAAwEiUGAAAYiRIDAACMRIkBAABGosQAAAAjUWIAAICRKDEAAMBIlBgAAGAkSgwAADASJQYAABiJEgMAAIxEiQEAAEaixAAAACNRYgAAgJEoMQAAwEiUGAAAYCRKDAAAMFJMJWblypVyuVxRm9frdY7btq2VK1fK5/MpKSlJEyZM0P79+6PO0dXVpQULFigzM1MpKSkqLS3VkSNHojLhcFh+v1+WZcmyLPn9fp04caL/VwkAAIacmFdirrvuOrW2tjrb3r17nWNr1qzR2rVrVVlZqcbGRnm9Xk2ePFkdHR1OJhAIqLq6WlVVVdq5c6dOnjypkpIS9fT0OJmysjIFg0HV1NSopqZGwWBQfr//PC8VAAAMJfExvyA+Pmr15VO2beuJJ57QI488ojvvvFOS9Mwzz8jj8ejZZ5/V3LlzFYlE9NRTT2nz5s2aNGmSJGnLli3Kzs7Wjh07NGXKFB04cEA1NTWqr69XQUGBJGnjxo0qLCzUW2+9pZEjR57P9QIAgCEi5pWYd955Rz6fTzk5Obr77rv17rvvSpKam5sVCoVUXFzsZN1ut8aPH69du3ZJkpqamnTq1KmojM/nU15enpPZvXu3LMtyCowkjRs3TpZlOZmz6erqUnt7e9QGAACGrphKTEFBgX75y1/qt7/9rTZu3KhQKKSioiL99a9/VSgUkiR5PJ6o13g8HudYKBRSYmKihg0bds5MVlZWr/fOyspyMmdTUVHhfIfGsixlZ2fHcmkAAMAwMZWY2267Td/61rc0ZswYTZo0SS+//LKkT35t9CmXyxX1Gtu2e+0705mZs+U/7zwrVqxQJBJxtpaWlj5dEwAAMNN53WKdkpKiMWPG6J133nG+J3PmaklbW5uzOuP1etXd3a1wOHzOzLFjx3q91/Hjx3ut8vxfbrdbaWlpURsAABi6zqvEdHV16cCBA7riiiuUk5Mjr9er2tpa53h3d7fq6upUVFQkScrPz1dCQkJUprW1Vfv27XMyhYWFikQiamhocDJ79uxRJBJxMgAAADHdnbRkyRLdfvvtuuqqq9TW1qYf/ehHam9v18yZM+VyuRQIBFReXq7c3Fzl5uaqvLxcycnJKisrkyRZlqVZs2Zp8eLFysjIUHp6upYsWeL8ekqSRo0apalTp2r27NnasGGDJGnOnDkqKSnhziQAAOCIqcQcOXJE99xzjz744AMNHz5c48aNU319va6++mpJ0tKlS9XZ2an58+crHA6roKBA27dvV2pqqnOOdevWKT4+XtOnT1dnZ6cmTpyoTZs2KS4uzsls3bpVCxcudO5iKi0tVWVl5UBcLwAAGCJctm3bgz2IC6G9vV2WZSkSiVyQ78eMWP7ygJ/zQntv1bTBHgIAAOcUy+c3fzsJAAAYiRIDAACMRIkBAABGosQAAAAjUWIAAICRKDEAAMBIlBgAAGAkSgwAADASJQYAABiJEgMAAIxEiQEAAEaixAAAACNRYgAAgJEoMQAAwEiUGAAAYCRKDAAAMBIlBgAAGIkSAwAAjESJAQAARqLEAAAAI1FiAACAkSgxAADASJQYAABgJEoMAAAwEiUGAAAYiRIDAACMRIkBAABGosQAAAAjUWIAAICRKDEAAMBIlBgAAGAkSgwAADDSeZWYiooKuVwuBQIBZ59t21q5cqV8Pp+SkpI0YcIE7d+/P+p1XV1dWrBggTIzM5WSkqLS0lIdOXIkKhMOh+X3+2VZlizLkt/v14kTJ85nuAAAYAjpd4lpbGzUk08+qeuvvz5q/5o1a7R27VpVVlaqsbFRXq9XkydPVkdHh5MJBAKqrq5WVVWVdu7cqZMnT6qkpEQ9PT1OpqysTMFgUDU1NaqpqVEwGJTf7+/vcAEAwBDTrxJz8uRJ3Xvvvdq4caOGDRvm7LdtW0888YQeeeQR3XnnncrLy9Mzzzyjjz76SM8++6wkKRKJ6KmnntJPfvITTZo0STfeeKO2bNmivXv3aseOHZKkAwcOqKamRv/xH/+hwsJCFRYWauPGjXrppZf01ltvDcBlAwAA0/WrxDz44IOaNm2aJk2aFLW/ublZoVBIxcXFzj63263x48dr165dkqSmpiadOnUqKuPz+ZSXl+dkdu/eLcuyVFBQ4GTGjRsny7KczJm6urrU3t4etQEAgKErPtYXVFVV6fXXX1djY2OvY6FQSJLk8Xii9ns8Hh06dMjJJCYmRq3gfJr59PWhUEhZWVm9zp+VleVkzlRRUaFHH3001ssBAACGimklpqWlRQ8//LC2bNmiyy+//DNzLpcr6mfbtnvtO9OZmbPlz3WeFStWKBKJOFtLS8s53w8AAJgtphLT1NSktrY25efnKz4+XvHx8aqrq9NPf/pTxcfHOyswZ66WtLW1Oce8Xq+6u7sVDofPmTl27Fiv9z9+/HivVZ5Pud1upaWlRW0AAGDoiqnETJw4UXv37lUwGHS2sWPH6t5771UwGNQ111wjr9er2tpa5zXd3d2qq6tTUVGRJCk/P18JCQlRmdbWVu3bt8/JFBYWKhKJqKGhwcns2bNHkUjEyQAAgC+2mL4Tk5qaqry8vKh9KSkpysjIcPYHAgGVl5crNzdXubm5Ki8vV3JyssrKyiRJlmVp1qxZWrx4sTIyMpSenq4lS5ZozJgxzheFR40apalTp2r27NnasGGDJGnOnDkqKSnRyJEjz/uiAQCA+WL+Yu/nWbp0qTo7OzV//nyFw2EVFBRo+/btSk1NdTLr1q1TfHy8pk+frs7OTk2cOFGbNm1SXFyck9m6dasWLlzo3MVUWlqqysrKgR4uAAAwlMu2bXuwB3EhtLe3y7IsRSKRC/L9mBHLXx7wc15o762aNthDAADgnGL5/OZvJwEAACNRYgAAgJEoMQAAwEiUGAAAYCRKDAAAMBIlBgAAGIkSAwAAjESJAQAARqLEAAAAI1FiAACAkSgxAADASJQYAABgJEoMAAAwEiUGAAAYiRIDAACMRIkBAABGosQAAAAjUWIAAICRKDEAAMBIlBgAAGAkSgwAADASJQYAABiJEgMAAIxEiQEAAEaixAAAACNRYgAAgJEoMQAAwEiUGAAAYCRKDAAAMBIlBgAAGIkSAwAAjESJAQAARoqpxKxfv17XX3+90tLSlJaWpsLCQv3mN79xjtu2rZUrV8rn8ykpKUkTJkzQ/v37o87R1dWlBQsWKDMzUykpKSotLdWRI0eiMuFwWH6/X5ZlybIs+f1+nThxov9XCQAAhpyYSsyVV16pVatW6bXXXtNrr72mb3zjG/rHf/xHp6isWbNGa9euVWVlpRobG+X1ejV58mR1dHQ45wgEAqqurlZVVZV27typkydPqqSkRD09PU6mrKxMwWBQNTU1qqmpUTAYlN/vH6BLBgAAQ4HLtm37fE6Qnp6uH//4x3rggQfk8/kUCAS0bNkySZ+sung8Hq1evVpz585VJBLR8OHDtXnzZs2YMUOSdPToUWVnZ2vbtm2aMmWKDhw4oNGjR6u+vl4FBQWSpPr6ehUWFurgwYMaOXJkn8bV3t4uy7IUiUSUlpZ2Ppd4ViOWvzzg57zQ3ls1bbCHAADAOcXy+d3v78T09PSoqqpKH374oQoLC9Xc3KxQKKTi4mIn43a7NX78eO3atUuS1NTUpFOnTkVlfD6f8vLynMzu3btlWZZTYCRp3LhxsizLyZxNV1eX2tvbozYAADB0xVxi9u7dqy996Utyu92aN2+eqqurNXr0aIVCIUmSx+OJyns8HudYKBRSYmKihg0bds5MVlZWr/fNyspyMmdTUVHhfIfGsixlZ2fHemkAAMAgMZeYkSNHKhgMqr6+Xt/5znc0c+ZMvfnmm85xl8sVlbdtu9e+M52ZOVv+886zYsUKRSIRZ2tpaenrJQEAAAPFXGISExP1d3/3dxo7dqwqKip0ww036N/+7d/k9XolqddqSVtbm7M64/V61d3drXA4fM7MsWPHer3v8ePHe63y/F9ut9u5a+rTDQAADF3n/ZwY27bV1dWlnJwceb1e1dbWOse6u7tVV1enoqIiSVJ+fr4SEhKiMq2trdq3b5+TKSwsVCQSUUNDg5PZs2ePIpGIkwEAAIiPJfz9739ft912m7Kzs9XR0aGqqir94Q9/UE1NjVwulwKBgMrLy5Wbm6vc3FyVl5crOTlZZWVlkiTLsjRr1iwtXrxYGRkZSk9P15IlSzRmzBhNmjRJkjRq1ChNnTpVs2fP1oYNGyRJc+bMUUlJSZ/vTAIAAENfTCXm2LFj8vv9am1tlWVZuv7661VTU6PJkydLkpYuXarOzk7Nnz9f4XBYBQUF2r59u1JTU51zrFu3TvHx8Zo+fbo6Ozs1ceJEbdq0SXFxcU5m69atWrhwoXMXU2lpqSorKwfiegEAwBBx3s+JuVTxnJjeeE4MAOBSd1GeEwMAADCYKDEAAMBIlBgAAGAkSgwAADASJQYAABiJEgMAAIxEiQEAAEaixAAAACNRYgAAgJEoMQAAwEiUGAAAYCRKDAAAMBIlBgAAGIkSAwAAjESJAQAARqLEAAAAI1FiAACAkeIHewC4eEYsf3mwhxCz91ZNG+whAAAuUazEAAAAI1FiAACAkSgxAADASJQYAABgJEoMAAAwEiUGAAAYiRIDAACMRIkBAABGosQAAAAjUWIAAICRKDEAAMBIlBgAAGAkSgwAADASJQYAABgpphJTUVGhm2++WampqcrKytIdd9yht956Kypj27ZWrlwpn8+npKQkTZgwQfv374/KdHV1acGCBcrMzFRKSopKS0t15MiRqEw4HJbf75dlWbIsS36/XydOnOjfVQIAgCEnphJTV1enBx98UPX19aqtrdXHH3+s4uJiffjhh05mzZo1Wrt2rSorK9XY2Civ16vJkyero6PDyQQCAVVXV6uqqko7d+7UyZMnVVJSop6eHidTVlamYDCompoa1dTUKBgMyu/3D8AlAwCAocBl27bd3xcfP35cWVlZqqur09e+9jXZti2fz6dAIKBly5ZJ+mTVxePxaPXq1Zo7d64ikYiGDx+uzZs3a8aMGZKko0ePKjs7W9u2bdOUKVN04MABjR49WvX19SooKJAk1dfXq7CwUAcPHtTIkSM/d2zt7e2yLEuRSERpaWn9vcTPNGL5ywN+TvT23qppgz0EAMBFFMvn93l9JyYSiUiS0tPTJUnNzc0KhUIqLi52Mm63W+PHj9euXbskSU1NTTp16lRUxufzKS8vz8ns3r1blmU5BUaSxo0bJ8uynMyZurq61N7eHrUBAIChq98lxrZtLVq0SLfeeqvy8vIkSaFQSJLk8Xiish6PxzkWCoWUmJioYcOGnTOTlZXV6z2zsrKczJkqKiqc789YlqXs7Oz+XhoAADBAv0vMQw89pD//+c/6z//8z17HXC5X1M+2bffad6YzM2fLn+s8K1asUCQScbaWlpa+XAYAADBUv0rMggUL9OKLL+qVV17RlVde6ez3er2S1Gu1pK2tzVmd8Xq96u7uVjgcPmfm2LFjvd73+PHjvVZ5PuV2u5WWlha1AQCAoSumEmPbth566CE9//zz+v3vf6+cnJyo4zk5OfJ6vaqtrXX2dXd3q66uTkVFRZKk/Px8JSQkRGVaW1u1b98+J1NYWKhIJKKGhgYns2fPHkUiEScDAAC+2OJjCT/44IN69tln9V//9V9KTU11Vlwsy1JSUpJcLpcCgYDKy8uVm5ur3NxclZeXKzk5WWVlZU521qxZWrx4sTIyMpSenq4lS5ZozJgxmjRpkiRp1KhRmjp1qmbPnq0NGzZIkubMmaOSkpI+3ZkEAACGvphKzPr16yVJEyZMiNr/9NNP6/7775ckLV26VJ2dnZo/f77C4bAKCgq0fft2paamOvl169YpPj5e06dPV2dnpyZOnKhNmzYpLi7OyWzdulULFy507mIqLS1VZWVlf64RAAAMQef1nJhLGc+JGRp4TgwAfLFctOfEAAAADBZKDAAAMBIlBgAAGIkSAwAAjESJAQAARqLEAAAAI1FiAACAkSgxAADASJQYAABgJEoMAAAwEiUGAAAYiRIDAACMRIkBAABGosQAAAAjUWIAAICRKDEAAMBIlBgAAGAkSgwAADASJQYAABiJEgMAAIxEiQEAAEaixAAAACNRYgAAgJEoMQAAwEiUGAAAYCRKDAAAMBIlBgAAGIkSAwAAjESJAQAARqLEAAAAI1FiAACAkSgxAADASDGXmD/+8Y+6/fbb5fP55HK59MILL0Qdt21bK1eulM/nU1JSkiZMmKD9+/dHZbq6urRgwQJlZmYqJSVFpaWlOnLkSFQmHA7L7/fLsixZliW/368TJ07EfIEAAGBoirnEfPjhh7rhhhtUWVl51uNr1qzR2rVrVVlZqcbGRnm9Xk2ePFkdHR1OJhAIqLq6WlVVVdq5c6dOnjypkpIS9fT0OJmysjIFg0HV1NSopqZGwWBQfr+/H5cIAACGIpdt23a/X+xyqbq6WnfccYekT1ZhfD6fAoGAli1bJumTVRePx6PVq1dr7ty5ikQiGj58uDZv3qwZM2ZIko4ePars7Gxt27ZNU6ZM0YEDBzR69GjV19eroKBAklRfX6/CwkIdPHhQI0eO/Nyxtbe3y7IsRSIRpaWl9fcSP9OI5S8P+DnR23urpg32EAAAF1Esn98D+p2Y5uZmhUIhFRcXO/vcbrfGjx+vXbt2SZKampp06tSpqIzP51NeXp6T2b17tyzLcgqMJI0bN06WZTmZM3V1dam9vT1qAwAAQ9eAlphQKCRJ8ng8Ufs9Ho9zLBQKKTExUcOGDTtnJisrq9f5s7KynMyZKioqnO/PWJal7Ozs874eAABw6bogdye5XK6on23b7rXvTGdmzpY/13lWrFihSCTibC0tLf0YOQAAMMWAlhiv1ytJvVZL2tranNUZr9er7u5uhcPhc2aOHTvW6/zHjx/vtcrzKbfbrbS0tKgNAAAMXQNaYnJycuT1elVbW+vs6+7uVl1dnYqKiiRJ+fn5SkhIiMq0trZq3759TqawsFCRSEQNDQ1OZs+ePYpEIk4GAAB8scXH+oKTJ0/qL3/5i/Nzc3OzgsGg0tPTddVVVykQCKi8vFy5ubnKzc1VeXm5kpOTVVZWJkmyLEuzZs3S4sWLlZGRofT0dC1ZskRjxozRpEmTJEmjRo3S1KlTNXv2bG3YsEGSNGfOHJWUlPTpziQAADD0xVxiXnvtNX396193fl60aJEkaebMmdq0aZOWLl2qzs5OzZ8/X+FwWAUFBdq+fbtSU1Od16xbt07x8fGaPn26Ojs7NXHiRG3atElxcXFOZuvWrVq4cKFzF1NpaelnPpsGAAB88ZzXc2IuZTwnZmjgOTEA8MUyaM+JAQAAuFgoMQAAwEiUGAAAYCRKDAAAMBIlBgAAGIkSAwAAjESJAQAARqLEAAAAI1FiAACAkSgxAADASJQYAABgpJj/ACRwMZn4N6r4e08AcHGwEgMAAIxEiQEAAEaixAAAACNRYgAAgJEoMQAAwEiUGAAAYCRKDAAAMBIlBgAAGIkSAwAAjESJAQAARqLEAAAAI1FiAACAkSgxAADASJQYAABgJEoMAAAwEiUGAAAYiRIDAACMRIkBAABGih/sAQBDzYjlLw/2EGL23qppgz0EAIgZKzEAAMBIl3yJ+fnPf66cnBxdfvnlys/P16uvvjrYQwIAAJeAS7rEPPfccwoEAnrkkUf0xhtv6B/+4R9022236fDhw4M9NAAAMMhctm3bgz2Iz1JQUKCbbrpJ69evd/aNGjVKd9xxhyoqKs752vb2dlmWpUgkorS0tAEfm4nfewCGEr7HAwxNsXx+X7Jf7O3u7lZTU5OWL18etb+4uFi7du3qle/q6lJXV5fzcyQSkfTJZFwIp7s+uiDnBdA3V333V4M9hJjte3TKYA8BuOR9+rndlzWWS7bEfPDBB+rp6ZHH44na7/F4FAqFeuUrKir06KOP9tqfnZ19wcYIALGwnhjsEQDm6OjokGVZ58xcsiXmUy6XK+pn27Z77ZOkFStWaNGiRc7Pp0+f1t/+9jdlZGScNd9X7e3tys7OVktLywX5tRR6Y84vPub84mPOLz7m/OLrz5zbtq2Ojg75fL7PzV6yJSYzM1NxcXG9Vl3a2tp6rc5Iktvtltvtjtr35S9/ecDGk5aWxj/6i4w5v/iY84uPOb/4mPOLL9Y5/7wVmE9dsncnJSYmKj8/X7W1tVH7a2trVVRUNEijAgAAl4pLdiVGkhYtWiS/36+xY8eqsLBQTz75pA4fPqx58+YN9tAAAMAgu6RLzIwZM/TXv/5Vjz32mFpbW5WXl6dt27bp6quvvmhjcLvd+uEPf9jrV1W4cJjzi485v/iY84uPOb/4LvScX9LPiQEAAPgsl+x3YgAAAM6FEgMAAIxEiQEAAEaixAAAACNRYj7Hz3/+c+Xk5Ojyyy9Xfn6+Xn311cEe0pBQUVGhm2++WampqcrKytIdd9yht956Kypj27ZWrlwpn8+npKQkTZgwQfv37x+kEQ89FRUVcrlcCgQCzj7mfOC9//77uu+++5SRkaHk5GR99atfVVNTk3OcOR9YH3/8sX7wgx8oJydHSUlJuuaaa/TYY4/p9OnTToY5Pz9//OMfdfvtt8vn88nlcumFF16IOt6X+e3q6tKCBQuUmZmplJQUlZaW6siRI7EPxsZnqqqqshMSEuyNGzfab775pv3www/bKSkp9qFDhwZ7aMabMmWK/fTTT9v79u2zg8GgPW3aNPuqq66yT5486WRWrVplp6am2r/+9a/tvXv32jNmzLCvuOIKu729fRBHPjQ0NDTYI0aMsK+//nr74YcfdvYz5wPrb3/7m3311Vfb999/v71nzx67ubnZ3rFjh/2Xv/zFyTDnA+tHP/qRnZGRYb/00kt2c3Oz/atf/cr+0pe+ZD/xxBNOhjk/P9u2bbMfeeQR+9e//rUtya6uro463pf5nTdvnv2Vr3zFrq2ttV9//XX761//un3DDTfYH3/8cUxjocScw9///d/b8+bNi9p37bXX2suXLx+kEQ1dbW1ttiS7rq7Otm3bPn36tO31eu1Vq1Y5mf/93/+1Lcuyf/GLXwzWMIeEjo4OOzc3166trbXHjx/vlBjmfOAtW7bMvvXWWz/zOHM+8KZNm2Y/8MADUfvuvPNO+7777rNtmzkfaGeWmL7M74kTJ+yEhAS7qqrKybz//vv2ZZddZtfU1MT0/vw66TN0d3erqalJxcXFUfuLi4u1a9euQRrV0BWJRCRJ6enpkqTm5maFQqGo+Xe73Ro/fjzzf54efPBBTZs2TZMmTYraz5wPvBdffFFjx47VXXfdpaysLN14443auHGjc5w5H3i33nqrfve73+ntt9+WJP3pT3/Szp079c1vflMSc36h9WV+m5qadOrUqaiMz+dTXl5ezP8NLukn9g6mDz74QD09Pb3+2KTH4+n1Rylxfmzb1qJFi3TrrbcqLy9Pkpw5Ptv8Hzp06KKPcaioqqrS66+/rsbGxl7HmPOB9+6772r9+vVatGiRvv/976uhoUELFy6U2+3Wt7/9beb8Ali2bJkikYiuvfZaxcXFqaenR48//rjuueceSfw7v9D6Mr+hUEiJiYkaNmxYr0ysn6+UmM/hcrmifrZtu9c+nJ+HHnpIf/7zn7Vz585ex5j/gdPS0qKHH35Y27dv1+WXX/6ZOeZ84Jw+fVpjx45VeXm5JOnGG2/U/v37tX79en372992csz5wHnuuee0ZcsWPfvss7ruuusUDAYVCATk8/k0c+ZMJ8ecX1j9md/+/Dfg10mfITMzU3Fxcb1aYVtbW6+Gif5bsGCBXnzxRb3yyiu68sornf1er1eSmP8B1NTUpLa2NuXn5ys+Pl7x8fGqq6vTT3/6U8XHxzvzypwPnCuuuEKjR4+O2jdq1CgdPnxYEv/OL4Tvfe97Wr58ue6++26NGTNGfr9f3/3ud1VRUSGJOb/Q+jK/Xq9X3d3dCofDn5npK0rMZ0hMTFR+fr5qa2uj9tfW1qqoqGiQRjV02Lathx56SM8//7x+//vfKycnJ+p4Tk6OvF5v1Px3d3errq6O+e+niRMnau/evQoGg842duxY3XvvvQoGg7rmmmuY8wF2yy239Hp0wNtvv+38EVv+nQ+8jz76SJddFv3RFhcX59xizZxfWH2Z3/z8fCUkJERlWltbtW/fvtj/G/Tr68hfEJ/eYv3UU0/Zb775ph0IBOyUlBT7vffeG+yhGe873/mObVmW/Yc//MFubW11to8++sjJrFq1yrYsy37++eftvXv32vfccw+3QQ6w/3t3km0z5wOtoaHBjo+Ptx9//HH7nXfesbdu3WonJyfbW7ZscTLM+cCaOXOm/ZWvfMW5xfr555+3MzMz7aVLlzoZ5vz8dHR02G+88Yb9xhtv2JLstWvX2m+88Ybz+JG+zO+8efPsK6+80t6xY4f9+uuv29/4xje4xfpC+Pd//3f76quvthMTE+2bbrrJuQUY50fSWbenn37ayZw+fdr+4Q9/aHu9Xtvtdttf+9rX7L179w7eoIegM0sMcz7w/vu//9vOy8uz3W63fe2119pPPvlk1HHmfGC1t7fbDz/8sH3VVVfZl19+uX3NNdfYjzzyiN3V1eVkmPPz88orr5z1/98zZ860bbtv89vZ2Wk/9NBDdnp6up2UlGSXlJTYhw8fjnksLtu27X6vGwEAAAwSvhMDAACMRIkBAABGosQAAAAjUWIAAICRKDEAAMBIlBgAAGAkSgwAADASJQYAABiJEgMAAIxEiQEAAEaixAAAACNRYgAAgJH+H+pPw7SKLPNqAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sequence_lengths = []\n",
    "\n",
    "for i in range(len(X_train)):\n",
    "  sequence_lengths.append(len(X_train[i]))\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.hist(sequence_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    11426.000000\n",
       "mean         9.224313\n",
       "std          7.202322\n",
       "min          1.000000\n",
       "25%          5.000000\n",
       "50%          7.000000\n",
       "75%         11.000000\n",
       "max         98.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(sequence_lengths).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "# Create sequences padding for X\n",
    "def pad_sequences(X, desired_sequence_length=205):\n",
    "  X_copy = deepcopy(X)\n",
    "\n",
    "  for i, x in enumerate(X):\n",
    "    x_seq_len = x.shape[0]\n",
    "    sequence_length_difference = desired_sequence_length - x_seq_len\n",
    "    \n",
    "    pad = np.zeros(shape=(sequence_length_difference, 200))\n",
    "\n",
    "    X_copy[i] = np.concatenate([x, pad])\n",
    "  \n",
    "  return np.array(X_copy).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11426, 205, 200)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = pad_sequences(X_train)\n",
    "\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11426,)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1583, 205, 200), (1583,))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val, y_val = df_to_X_y(dev_df)\n",
    "X_val = pad_sequences(X_val)\n",
    "\n",
    "X_val.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3166, 205, 200), (3166,))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test, y_test = df_to_X_y(test_df)\n",
    "X_test = pad_sequences(X_test)\n",
    "\n",
    "X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Generate LSTM Model\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "from keras.models import Sequential\n",
    "\n",
    "model = Sequential([])\n",
    "\n",
    "model.add(layers.Input(shape=(205, 200)))\n",
    "model.add(layers.LSTM(128, return_sequences=True))\n",
    "model.add(layers.Dropout(0.2))\n",
    "model.add(layers.LSTM(64, return_sequences=True))\n",
    "model.add(layers.Dropout(0.2))\n",
    "model.add(layers.LSTM(32, return_sequences=True))\n",
    "model.add(layers.Dropout(0.2))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(3, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 205, 128)          168448    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 205, 128)          0         \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 205, 64)           49408     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 205, 64)           0         \n",
      "                                                                 \n",
      " lstm_2 (LSTM)               (None, 205, 32)           12416     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 205, 32)           0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 6560)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 3)                 19683     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 249955 (976.39 KB)\n",
      "Trainable params: 249955 (976.39 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.losses import BinaryCrossentropy\n",
    "from keras.optimizers import Adam\n",
    "from keras.metrics import AUC\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "# Import the legacy optimizer\n",
    "from keras.optimizers import legacy\n",
    "\n",
    "cp = ModelCheckpoint('model/', save_best_only=True)\n",
    "\n",
    "# Use the legacy Adam optimizer\n",
    "optimizer = legacy.Adam(learning_rate=0.01)\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiments\n",
       "2    5643\n",
       "0    5325\n",
       "1     458\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frequencies = pd.value_counts(train_df['sentiments'])\n",
    "\n",
    "frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 2.1457276995305166, 1: 24.94759825327511, 2: 2.024809498493709}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = {0: frequencies.sum() / frequencies[0], 1: frequencies.sum() / frequencies[1], 2: frequencies.sum() / frequencies[2]}\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "358/358 [==============================] - ETA: 0s - loss: 1.9360 - accuracy: 0.7511INFO:tensorflow:Assets written to: model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "358/358 [==============================] - 94s 255ms/step - loss: 1.9360 - accuracy: 0.7511 - val_loss: 0.4746 - val_accuracy: 0.7934\n",
      "Epoch 2/20\n",
      "358/358 [==============================] - 83s 233ms/step - loss: 1.5587 - accuracy: 0.8040 - val_loss: 0.5833 - val_accuracy: 0.7631\n",
      "Epoch 3/20\n",
      "358/358 [==============================] - ETA: 0s - loss: 1.4189 - accuracy: 0.8178INFO:tensorflow:Assets written to: model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "358/358 [==============================] - 92s 256ms/step - loss: 1.4189 - accuracy: 0.8178 - val_loss: 0.4661 - val_accuracy: 0.8023\n",
      "Epoch 4/20\n",
      "358/358 [==============================] - 84s 234ms/step - loss: 1.3637 - accuracy: 0.8317 - val_loss: 0.4882 - val_accuracy: 0.8010\n",
      "Epoch 5/20\n",
      "358/358 [==============================] - ETA: 0s - loss: 1.2294 - accuracy: 0.8464INFO:tensorflow:Assets written to: model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "358/358 [==============================] - 92s 258ms/step - loss: 1.2294 - accuracy: 0.8464 - val_loss: 0.3955 - val_accuracy: 0.8446\n",
      "Epoch 6/20\n",
      "358/358 [==============================] - ETA: 0s - loss: 1.1510 - accuracy: 0.8526INFO:tensorflow:Assets written to: model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "358/358 [==============================] - 93s 259ms/step - loss: 1.1510 - accuracy: 0.8526 - val_loss: 0.3518 - val_accuracy: 0.8591\n",
      "Epoch 7/20\n",
      "358/358 [==============================] - ETA: 0s - loss: 1.1062 - accuracy: 0.8552INFO:tensorflow:Assets written to: model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "358/358 [==============================] - 91s 255ms/step - loss: 1.1062 - accuracy: 0.8552 - val_loss: 0.2779 - val_accuracy: 0.8939\n",
      "Epoch 8/20\n",
      "358/358 [==============================] - 85s 236ms/step - loss: 0.9943 - accuracy: 0.8678 - val_loss: 0.3131 - val_accuracy: 0.8812\n",
      "Epoch 9/20\n",
      "358/358 [==============================] - 84s 235ms/step - loss: 0.9389 - accuracy: 0.8763 - val_loss: 0.3312 - val_accuracy: 0.8692\n",
      "Epoch 10/20\n",
      "358/358 [==============================] - 84s 236ms/step - loss: 0.9137 - accuracy: 0.8775 - val_loss: 0.3142 - val_accuracy: 0.8705\n",
      "Epoch 11/20\n",
      "358/358 [==============================] - 85s 237ms/step - loss: 0.8294 - accuracy: 0.8901 - val_loss: 0.3081 - val_accuracy: 0.8850\n",
      "Epoch 12/20\n",
      "358/358 [==============================] - 87s 243ms/step - loss: 0.7487 - accuracy: 0.8975 - val_loss: 0.3919 - val_accuracy: 0.8421\n",
      "Epoch 13/20\n",
      "358/358 [==============================] - 98s 274ms/step - loss: 0.7017 - accuracy: 0.9050 - val_loss: 0.3109 - val_accuracy: 0.8913\n",
      "Epoch 14/20\n",
      "358/358 [==============================] - ETA: 0s - loss: 0.7207 - accuracy: 0.9039INFO:tensorflow:Assets written to: model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "358/358 [==============================] - 101s 283ms/step - loss: 0.7207 - accuracy: 0.9039 - val_loss: 0.2776 - val_accuracy: 0.9015\n",
      "Epoch 15/20\n",
      "358/358 [==============================] - 89s 248ms/step - loss: 0.6066 - accuracy: 0.9163 - val_loss: 0.3135 - val_accuracy: 0.8977\n",
      "Epoch 16/20\n",
      "358/358 [==============================] - 94s 262ms/step - loss: 0.5767 - accuracy: 0.9212 - val_loss: 0.2941 - val_accuracy: 0.9090\n",
      "Epoch 17/20\n",
      "358/358 [==============================] - 95s 265ms/step - loss: 0.5621 - accuracy: 0.9248 - val_loss: 0.3400 - val_accuracy: 0.8920\n",
      "Epoch 18/20\n",
      "358/358 [==============================] - 96s 269ms/step - loss: 0.5703 - accuracy: 0.9219 - val_loss: 0.3423 - val_accuracy: 0.8812\n",
      "Epoch 19/20\n",
      "358/358 [==============================] - 96s 267ms/step - loss: 0.4821 - accuracy: 0.9329 - val_loss: 0.3166 - val_accuracy: 0.9084\n",
      "Epoch 20/20\n",
      "358/358 [==============================] - 95s 266ms/step - loss: 0.4900 - accuracy: 0.9338 - val_loss: 0.3398 - val_accuracy: 0.9097\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2e4316890>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=20, callbacks=[cp], class_weight=weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "# Assuming you have trained and saved your model as follows\n",
    "model.save(\"models/lstm_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
